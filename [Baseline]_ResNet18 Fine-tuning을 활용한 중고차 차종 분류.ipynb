{"cells":[{"cell_type":"markdown","metadata":{"id":"5VshnXqrPMEq"},"source":["# Import"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfxoVXq9PMEq","executionInfo":{"status":"ok","timestamp":1748131579025,"user_tz":-540,"elapsed":10937,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}},"outputId":"2a6a665e-6827-4737-8a7d-56020e2e4dbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import os\n","import random\n","\n","import pandas as pd\n","import numpy as np\n","\n","from PIL import Image\n","from tqdm import tqdm\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader, Subset\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from torch import nn, optim\n","\n","from sklearn.metrics import log_loss\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FgSOCeu9PVID","executionInfo":{"status":"ok","timestamp":1748131595217,"user_tz":-540,"elapsed":16194,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}},"outputId":"8ad92a06-0f3a-4ba5-fcfb-175436043ec8","collapsed":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# 드라이브 -> 코랩으로 이미지 로드하는 속도가 느려서 학습 속도가 느려짐\n","# /content/dataset에 이미지를 저장하면 빨라질 것으로 예상됨\n","import zipfile\n","\n","# 파일 경로 입력\n","zip_file_name = '/content/drive/MyDrive/Colab Notebooks/HAI-Hecto-AI-Challenge-2025/data.zip'\n","\n","# 압축 해제할 경로 입력\n","extraction_dir = '/content/dataset'\n","\n","# 압축 해제\n","with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n","    zip_ref.extractall(extraction_dir)"],"metadata":{"id":"fYgmpHh-l1Lj","executionInfo":{"status":"ok","timestamp":1748131672140,"user_tz":-540,"elapsed":76921,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5s2yQ7KIPMEr"},"source":["# Hyperparameter Setting"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"O2b33OZJPMEr","executionInfo":{"status":"ok","timestamp":1748131672144,"user_tz":-540,"elapsed":1,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["CFG = {\n","    'IMG_SIZE': 224,\n","    'BATCH_SIZE': 64,\n","    'EPOCHS': 10,\n","    'LEARNING_RATE': 1e-4,\n","    'SEED' : 42\n","}"]},{"cell_type":"markdown","metadata":{"id":"2vO1W2YaPMEr"},"source":["# Fixed RandomSeed"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"K15C96exPMEr","executionInfo":{"status":"ok","timestamp":1748131672146,"user_tz":-540,"elapsed":1,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed_everything(CFG['SEED']) # Seed 고정"]},{"cell_type":"markdown","metadata":{"id":"Fssf6A9xPMEr"},"source":["# CustomDataset"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"tMcep3qNPMEr","executionInfo":{"status":"ok","timestamp":1748131672147,"user_tz":-540,"elapsed":0,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["class CustomImageDataset(Dataset):\n","    def __init__(self, root_dir, transform=None, is_test=False):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.is_test = is_test\n","        self.samples = []\n","\n","        if is_test:\n","            # 테스트셋: 라벨 없이 이미지 경로만 저장\n","            for fname in sorted(os.listdir(root_dir)):\n","                if fname.lower().endswith(('.jpg')):\n","                    img_path = os.path.join(root_dir, fname)\n","                    self.samples.append((img_path,))\n","        else:\n","            # 학습셋: 클래스별 폴더 구조에서 라벨 추출\n","            self.classes = sorted(os.listdir(root_dir))\n","            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n","\n","            for cls_name in self.classes:\n","                cls_folder = os.path.join(root_dir, cls_name)\n","                for fname in os.listdir(cls_folder):\n","                    if fname.lower().endswith(('.jpg')):\n","                        img_path = os.path.join(cls_folder, fname)\n","                        label = self.class_to_idx[cls_name]\n","                        self.samples.append((img_path, label))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        if self.is_test:\n","            img_path = self.samples[idx][0]\n","            image = Image.open(img_path).convert('RGB')\n","            if self.transform:\n","                image = self.transform(image)\n","            return image\n","        else:\n","            img_path, label = self.samples[idx]\n","            image = Image.open(img_path).convert('RGB')\n","            if self.transform:\n","                image = self.transform(image)\n","            return image, label\n"]},{"cell_type":"markdown","metadata":{"id":"TE7MM7MKPMEs"},"source":["# Data Load"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ni-tJoS6PMEs","executionInfo":{"status":"ok","timestamp":1748131672149,"user_tz":-540,"elapsed":1,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["train_root = '/content/dataset/train'\n","test_root = '/content/dataset/test'"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"O04pFQbVPMEs","executionInfo":{"status":"ok","timestamp":1748131672150,"user_tz":-540,"elapsed":0,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["train_transform = transforms.Compose([\n","    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PoAq9U4zPMEs","executionInfo":{"status":"ok","timestamp":1748131672500,"user_tz":-540,"elapsed":349,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}},"outputId":"ce8026f3-7497-4dfa-98e9-096de62adfe0"},"outputs":[{"output_type":"stream","name":"stdout","text":["총 이미지 수: 33137\n","train 이미지 수: 26509, valid 이미지 수: 6628\n"]}],"source":["# 전체 데이터셋 로드\n","full_dataset = CustomImageDataset(train_root, transform=None)\n","print(f\"총 이미지 수: {len(full_dataset)}\")\n","\n","targets = [label for _, label in full_dataset.samples]\n","class_names = full_dataset.classes\n","\n","# Stratified Split\n","train_idx, val_idx = train_test_split(\n","    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",")\n","\n","# Subset + transform 각각 적용\n","train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n","val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n","print(f'train 이미지 수: {len(train_dataset)}, valid 이미지 수: {len(val_dataset)}')\n","\n","\n","# DataLoader 정의\n","train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"4oxwOemiPMEs"},"source":["# Model Define"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"6bg-vt6MPMEs","executionInfo":{"status":"ok","timestamp":1748131672504,"user_tz":-540,"elapsed":2,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["class BaseModel(nn.Module):\n","    def __init__(self, num_classes):\n","        super(BaseModel, self).__init__()\n","        self.backbone = models.resnet18(pretrained=True)  # ResNet18 모델 불러오기\n","        self.feature_dim = self.backbone.fc.in_features\n","        self.backbone.fc = nn.Identity()  # feature extractor로만 사용\n","        self.head = nn.Linear(self.feature_dim, num_classes)  # 분류기\n","\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.head(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"nXjsQGakPMEs"},"source":["# Train/ Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rPNtlPjGPMEs","outputId":"5cb5d34a-68bf-453b-9b13-8305541bb867"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 62.5MB/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[Execute Model Training on cuda]\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["[Epoch 1/10] Training: 100%|██████████| 415/415 [04:32<00:00,  1.52it/s]\n","[Epoch 1/10] Validation: 100%|██████████| 104/104 [00:50<00:00,  2.05it/s]\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss : 4.1608 || Valid Loss : 2.2727 | Valid Accuracy : 70.5190%\n","📦 Best model saved at epoch 1 (logloss: 2.2713)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["[Epoch 2/10] Training: 100%|██████████| 415/415 [04:13<00:00,  1.63it/s]\n","[Epoch 2/10] Validation: 100%|██████████| 104/104 [00:48<00:00,  2.14it/s]\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss : 1.2921 || Valid Loss : 0.7625 | Valid Accuracy : 86.6476%\n","📦 Best model saved at epoch 2 (logloss: 0.7619)\n"]},{"output_type":"stream","name":"stderr","text":["[Epoch 3/10] Training:  76%|███████▌  | 316/415 [03:11<00:57,  1.74it/s]"]}],"source":["model = BaseModel(num_classes=len(class_names)).to(device)\n","best_logloss = float('inf')\n","\n","print('[Execute Model Training on {}]'.format(device))\n","\n","# 손실 함수\n","criterion = nn.CrossEntropyLoss()\n","\n","# 옵티마이저\n","optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n","\n","\n","CFG['EPOCHS'] = 10\n","\n","# 학습 및 검증 루프\n","for epoch in range(CFG['EPOCHS']):\n","    # Train\n","    model.train()\n","    train_loss = 0.0\n","    for images, labels in tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)  # logits\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    avg_train_loss = train_loss / len(train_loader)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    all_probs = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            # Accuracy\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","            # LogLoss\n","            probs = F.softmax(outputs, dim=1)\n","            all_probs.extend(probs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    avg_val_loss = val_loss / len(val_loader)\n","    val_accuracy = 100 * correct / total\n","    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n","\n","    # 결과 출력\n","    print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.4f}%\")\n","\n","    # Best model 저장\n","    if val_logloss < best_logloss:\n","        best_logloss = val_logloss\n","        torch.save(model.state_dict(), f'best_model.pth')\n","        print(f\"📦 Best model saved at epoch {epoch+1} (logloss: {val_logloss:.4f})\")"]},{"cell_type":"markdown","metadata":{"id":"X3JuJ6MuPMEs"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVWZtDNWPMEs"},"outputs":[],"source":["test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n","test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AR826n4RPMEs"},"outputs":[],"source":["# 저장된 모델 로드\n","model = BaseModel(num_classes=len(class_names))\n","model.load_state_dict(torch.load('best_model.pth', map_location=device))\n","model.to(device)\n","\n","# 추론\n","model.eval()\n","results = []\n","\n","with torch.no_grad():\n","    for images in test_loader:\n","        images = images.to(device)\n","        outputs = model(images)\n","        probs = F.softmax(outputs, dim=1)\n","\n","        # 각 배치의 확률을 리스트로 변환\n","        for prob in probs.cpu():  # prob: (num_classes,)\n","            result = {\n","                class_names[i]: prob[i].item()\n","                for i in range(len(class_names))\n","            }\n","            results.append(result)\n","\n","pred = pd.DataFrame(results)"]},{"cell_type":"markdown","metadata":{"id":"Q3uvmWLaPMEt"},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqY5jhyqPMEt"},"outputs":[],"source":["submission = pd.read_csv('/content/dataset/sample_submission.csv', encoding='utf-8-sig')\n","\n","# 'ID' 컬럼을 제외한 클래스 컬럼 정렬\n","class_columns = submission.columns[1:]\n","pred = pred[class_columns]\n","\n","submission[class_columns] = pred.values\n","submission.to_csv('/content/dataset/baseline_submission.csv', index=False, encoding='utf-8-sig')"]},{"cell_type":"code","source":[],"metadata":{"id":"ce-juuf5Z-Fp"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}