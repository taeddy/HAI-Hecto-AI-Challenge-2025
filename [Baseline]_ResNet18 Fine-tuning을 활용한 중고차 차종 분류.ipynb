{"cells":[{"cell_type":"markdown","metadata":{"id":"5VshnXqrPMEq"},"source":["# Import"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfxoVXq9PMEq","executionInfo":{"status":"ok","timestamp":1747971879012,"user_tz":-540,"elapsed":16384,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}},"outputId":"d2df87eb-1616-43b1-dc1d-d28569a2cd0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n"]}],"source":["import os\n","import random\n","\n","import pandas as pd\n","import numpy as np\n","\n","from PIL import Image\n","from tqdm import tqdm\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader, Subset\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from torch import nn, optim\n","\n","from sklearn.metrics import log_loss\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FgSOCeu9PVID","executionInfo":{"status":"ok","timestamp":1747971862631,"user_tz":-540,"elapsed":17424,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}},"outputId":"b1aa143e-0a0f-4f5d-b8e4-aca943c4528f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"5s2yQ7KIPMEr"},"source":["# Hyperparameter Setting"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"O2b33OZJPMEr","executionInfo":{"status":"ok","timestamp":1747971884011,"user_tz":-540,"elapsed":4,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["CFG = {\n","    'IMG_SIZE': 224,\n","    'BATCH_SIZE': 64,\n","    'EPOCHS': 10,\n","    'LEARNING_RATE': 1e-4,\n","    'SEED' : 42\n","}"]},{"cell_type":"markdown","metadata":{"id":"2vO1W2YaPMEr"},"source":["# Fixed RandomSeed"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"K15C96exPMEr","executionInfo":{"status":"ok","timestamp":1747971896776,"user_tz":-540,"elapsed":16,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed_everything(CFG['SEED']) # Seed 고정"]},{"cell_type":"markdown","metadata":{"id":"Fssf6A9xPMEr"},"source":["# CustomDataset"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"tMcep3qNPMEr","executionInfo":{"status":"ok","timestamp":1747971920356,"user_tz":-540,"elapsed":3,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["class CustomImageDataset(Dataset):\n","    def __init__(self, root_dir, transform=None, is_test=False):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.is_test = is_test\n","        self.samples = []\n","\n","        if is_test:\n","            # 테스트셋: 라벨 없이 이미지 경로만 저장\n","            for fname in sorted(os.listdir(root_dir)):\n","                if fname.lower().endswith(('.jpg')):\n","                    img_path = os.path.join(root_dir, fname)\n","                    self.samples.append((img_path,))\n","        else:\n","            # 학습셋: 클래스별 폴더 구조에서 라벨 추출\n","            self.classes = sorted(os.listdir(root_dir))\n","            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n","\n","            for cls_name in self.classes:\n","                cls_folder = os.path.join(root_dir, cls_name)\n","                for fname in os.listdir(cls_folder):\n","                    if fname.lower().endswith(('.jpg')):\n","                        img_path = os.path.join(cls_folder, fname)\n","                        label = self.class_to_idx[cls_name]\n","                        self.samples.append((img_path, label))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        if self.is_test:\n","            img_path = self.samples[idx][0]\n","            image = Image.open(img_path).convert('RGB')\n","            if self.transform:\n","                image = self.transform(image)\n","            return image\n","        else:\n","            img_path, label = self.samples[idx]\n","            image = Image.open(img_path).convert('RGB')\n","            if self.transform:\n","                image = self.transform(image)\n","            return image, label\n"]},{"cell_type":"markdown","metadata":{"id":"TE7MM7MKPMEs"},"source":["# Data Load"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ni-tJoS6PMEs","executionInfo":{"status":"ok","timestamp":1747971961762,"user_tz":-540,"elapsed":6,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["train_root = '/content/drive/MyDrive/Colab Notebooks/HAI/data/train'\n","test_root = '/content/drive/MyDrive/Colab Notebooks/HAI/data/test'"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"O04pFQbVPMEs","executionInfo":{"status":"ok","timestamp":1747971938178,"user_tz":-540,"elapsed":4,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["train_transform = transforms.Compose([\n","    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PoAq9U4zPMEs","executionInfo":{"status":"ok","timestamp":1747972008996,"user_tz":-540,"elapsed":46250,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}},"outputId":"3b02bd56-a4c2-4ddd-842b-bd3560f9d893"},"outputs":[{"output_type":"stream","name":"stdout","text":["총 이미지 수: 33137\n","train 이미지 수: 26509, valid 이미지 수: 6628\n"]}],"source":["# 전체 데이터셋 로드\n","full_dataset = CustomImageDataset(train_root, transform=None)\n","print(f\"총 이미지 수: {len(full_dataset)}\")\n","\n","targets = [label for _, label in full_dataset.samples]\n","class_names = full_dataset.classes\n","\n","# Stratified Split\n","train_idx, val_idx = train_test_split(\n","    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",")\n","\n","# Subset + transform 각각 적용\n","train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n","val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n","print(f'train 이미지 수: {len(train_dataset)}, valid 이미지 수: {len(val_dataset)}')\n","\n","\n","# DataLoader 정의\n","train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"4oxwOemiPMEs"},"source":["# Model Define"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"6bg-vt6MPMEs","executionInfo":{"status":"ok","timestamp":1747972013087,"user_tz":-540,"elapsed":5,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["class BaseModel(nn.Module):\n","    def __init__(self, num_classes):\n","        super(BaseModel, self).__init__()\n","        self.backbone = models.resnet18(pretrained=True)  # ResNet18 모델 불러오기\n","        self.feature_dim = self.backbone.fc.in_features\n","        self.backbone.fc = nn.Identity()  # feature extractor로만 사용\n","        self.head = nn.Linear(self.feature_dim, num_classes)  # 분류기\n","\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.head(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"nXjsQGakPMEs"},"source":["# Train/ Validation"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"rPNtlPjGPMEs","executionInfo":{"status":"error","timestamp":1747973083356,"user_tz":-540,"elapsed":1065327,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}},"outputId":"8b8cfa00-cd86-4bb9-fca5-cc9ae9d2d4f3"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 148MB/s]\n","[Epoch 1/10] Training:   7%|▋         | 28/415 [17:44<4:05:12, 38.02s/it]\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/HAI/data/train/뉴QM3_2018_2019/뉴QM3_2018_2019_0078.jpg'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-a4c0ddaef89a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-a4159f8600fd>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/HAI/data/train/뉴QM3_2018_2019/뉴QM3_2018_2019_0078.jpg'"]}],"source":["model = BaseModel(num_classes=len(class_names)).to(device)\n","best_logloss = float('inf')\n","\n","# 손실 함수\n","criterion = nn.CrossEntropyLoss()\n","\n","# 옵티마이저\n","optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n","\n","# 학습 및 검증 루프\n","for epoch in range(CFG['EPOCHS']):\n","    # Train\n","    model.train()\n","    train_loss = 0.0\n","    for images, labels in tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)  # logits\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    avg_train_loss = train_loss / len(train_loader)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    all_probs = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            # Accuracy\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","            # LogLoss\n","            probs = F.softmax(outputs, dim=1)\n","            all_probs.extend(probs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    avg_val_loss = val_loss / len(val_loader)\n","    val_accuracy = 100 * correct / total\n","    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n","\n","    # 결과 출력\n","    print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.4f}%\")\n","\n","    # Best model 저장\n","    if val_logloss < best_logloss:\n","        best_logloss = val_logloss\n","        torch.save(model.state_dict(), f'best_model.pth')\n","        print(f\"📦 Best model saved at epoch {epoch+1} (logloss: {val_logloss:.4f})\")"]},{"cell_type":"markdown","metadata":{"id":"X3JuJ6MuPMEs"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVWZtDNWPMEs"},"outputs":[],"source":["test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n","test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AR826n4RPMEs"},"outputs":[],"source":["# 저장된 모델 로드\n","model = BaseModel(num_classes=len(class_names))\n","model.load_state_dict(torch.load('best_model.pth', map_location=device))\n","model.to(device)\n","\n","# 추론\n","model.eval()\n","results = []\n","\n","with torch.no_grad():\n","    for images in test_loader:\n","        images = images.to(device)\n","        outputs = model(images)\n","        probs = F.softmax(outputs, dim=1)\n","\n","        # 각 배치의 확률을 리스트로 변환\n","        for prob in probs.cpu():  # prob: (num_classes,)\n","            result = {\n","                class_names[i]: prob[i].item()\n","                for i in range(len(class_names))\n","            }\n","            results.append(result)\n","\n","pred = pd.DataFrame(results)"]},{"cell_type":"markdown","metadata":{"id":"Q3uvmWLaPMEt"},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqY5jhyqPMEt"},"outputs":[],"source":["submission = pd.read_csv('./sample_submission.csv', encoding='utf-8-sig')\n","\n","# 'ID' 컬럼을 제외한 클래스 컬럼 정렬\n","class_columns = submission.columns[1:]\n","pred = pred[class_columns]\n","\n","submission[class_columns] = pred.values\n","submission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')"]}],"metadata":{"kernelspec":{"display_name":"test_39","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}