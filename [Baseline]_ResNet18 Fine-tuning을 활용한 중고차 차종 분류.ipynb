{"cells":[{"cell_type":"markdown","metadata":{"id":"5VshnXqrPMEq"},"source":["# Import"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bfxoVXq9PMEq","executionInfo":{"status":"ok","timestamp":1748131579025,"user_tz":-540,"elapsed":10937,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}},"outputId":"2a6a665e-6827-4737-8a7d-56020e2e4dbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import os\n","import random\n","\n","import pandas as pd\n","import numpy as np\n","\n","from PIL import Image\n","from tqdm import tqdm\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader, Subset\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from torch import nn, optim\n","\n","from sklearn.metrics import log_loss\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FgSOCeu9PVID","executionInfo":{"status":"ok","timestamp":1748131595217,"user_tz":-540,"elapsed":16194,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}},"outputId":"8ad92a06-0f3a-4ba5-fcfb-175436043ec8","collapsed":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# ë“œë¼ì´ë¸Œ -> ì½”ë©ìœ¼ë¡œ ì´ë¯¸ì§€ ë¡œë“œí•˜ëŠ” ì†ë„ê°€ ëŠë ¤ì„œ í•™ìŠµ ì†ë„ê°€ ëŠë ¤ì§\n","# /content/datasetì— ì´ë¯¸ì§€ë¥¼ ì €ì¥í•˜ë©´ ë¹¨ë¼ì§ˆ ê²ƒìœ¼ë¡œ ì˜ˆìƒë¨\n","import zipfile\n","\n","# íŒŒì¼ ê²½ë¡œ ì…ë ¥\n","zip_file_name = '/content/drive/MyDrive/Colab Notebooks/HAI-Hecto-AI-Challenge-2025/data.zip'\n","\n","# ì••ì¶• í•´ì œí•  ê²½ë¡œ ì…ë ¥\n","extraction_dir = '/content/dataset'\n","\n","# ì••ì¶• í•´ì œ\n","with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n","    zip_ref.extractall(extraction_dir)"],"metadata":{"id":"fYgmpHh-l1Lj","executionInfo":{"status":"ok","timestamp":1748131672140,"user_tz":-540,"elapsed":76921,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5s2yQ7KIPMEr"},"source":["# Hyperparameter Setting"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"O2b33OZJPMEr","executionInfo":{"status":"ok","timestamp":1748131672144,"user_tz":-540,"elapsed":1,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["CFG = {\n","    'IMG_SIZE': 224,\n","    'BATCH_SIZE': 64,\n","    'EPOCHS': 10,\n","    'LEARNING_RATE': 1e-4,\n","    'SEED' : 42\n","}"]},{"cell_type":"markdown","metadata":{"id":"2vO1W2YaPMEr"},"source":["# Fixed RandomSeed"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"K15C96exPMEr","executionInfo":{"status":"ok","timestamp":1748131672146,"user_tz":-540,"elapsed":1,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed_everything(CFG['SEED']) # Seed ê³ ì •"]},{"cell_type":"markdown","metadata":{"id":"Fssf6A9xPMEr"},"source":["# CustomDataset"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"tMcep3qNPMEr","executionInfo":{"status":"ok","timestamp":1748131672147,"user_tz":-540,"elapsed":0,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["class CustomImageDataset(Dataset):\n","    def __init__(self, root_dir, transform=None, is_test=False):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.is_test = is_test\n","        self.samples = []\n","\n","        if is_test:\n","            # í…ŒìŠ¤íŠ¸ì…‹: ë¼ë²¨ ì—†ì´ ì´ë¯¸ì§€ ê²½ë¡œë§Œ ì €ì¥\n","            for fname in sorted(os.listdir(root_dir)):\n","                if fname.lower().endswith(('.jpg')):\n","                    img_path = os.path.join(root_dir, fname)\n","                    self.samples.append((img_path,))\n","        else:\n","            # í•™ìŠµì…‹: í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡°ì—ì„œ ë¼ë²¨ ì¶”ì¶œ\n","            self.classes = sorted(os.listdir(root_dir))\n","            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n","\n","            for cls_name in self.classes:\n","                cls_folder = os.path.join(root_dir, cls_name)\n","                for fname in os.listdir(cls_folder):\n","                    if fname.lower().endswith(('.jpg')):\n","                        img_path = os.path.join(cls_folder, fname)\n","                        label = self.class_to_idx[cls_name]\n","                        self.samples.append((img_path, label))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        if self.is_test:\n","            img_path = self.samples[idx][0]\n","            image = Image.open(img_path).convert('RGB')\n","            if self.transform:\n","                image = self.transform(image)\n","            return image\n","        else:\n","            img_path, label = self.samples[idx]\n","            image = Image.open(img_path).convert('RGB')\n","            if self.transform:\n","                image = self.transform(image)\n","            return image, label\n"]},{"cell_type":"markdown","metadata":{"id":"TE7MM7MKPMEs"},"source":["# Data Load"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ni-tJoS6PMEs","executionInfo":{"status":"ok","timestamp":1748131672149,"user_tz":-540,"elapsed":1,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["train_root = '/content/dataset/train'\n","test_root = '/content/dataset/test'"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"O04pFQbVPMEs","executionInfo":{"status":"ok","timestamp":1748131672150,"user_tz":-540,"elapsed":0,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["train_transform = transforms.Compose([\n","    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PoAq9U4zPMEs","executionInfo":{"status":"ok","timestamp":1748131672500,"user_tz":-540,"elapsed":349,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}},"outputId":"ce8026f3-7497-4dfa-98e9-096de62adfe0"},"outputs":[{"output_type":"stream","name":"stdout","text":["ì´ ì´ë¯¸ì§€ ìˆ˜: 33137\n","train ì´ë¯¸ì§€ ìˆ˜: 26509, valid ì´ë¯¸ì§€ ìˆ˜: 6628\n"]}],"source":["# ì „ì²´ ë°ì´í„°ì…‹ ë¡œë“œ\n","full_dataset = CustomImageDataset(train_root, transform=None)\n","print(f\"ì´ ì´ë¯¸ì§€ ìˆ˜: {len(full_dataset)}\")\n","\n","targets = [label for _, label in full_dataset.samples]\n","class_names = full_dataset.classes\n","\n","# Stratified Split\n","train_idx, val_idx = train_test_split(\n","    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",")\n","\n","# Subset + transform ê°ê° ì ìš©\n","train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n","val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n","print(f'train ì´ë¯¸ì§€ ìˆ˜: {len(train_dataset)}, valid ì´ë¯¸ì§€ ìˆ˜: {len(val_dataset)}')\n","\n","\n","# DataLoader ì •ì˜\n","train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"4oxwOemiPMEs"},"source":["# Model Define"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"6bg-vt6MPMEs","executionInfo":{"status":"ok","timestamp":1748131672504,"user_tz":-540,"elapsed":2,"user":{"displayName":"taeddy j.","userId":"13529776384281333825"}}},"outputs":[],"source":["class BaseModel(nn.Module):\n","    def __init__(self, num_classes):\n","        super(BaseModel, self).__init__()\n","        self.backbone = models.resnet18(pretrained=True)  # ResNet18 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n","        self.feature_dim = self.backbone.fc.in_features\n","        self.backbone.fc = nn.Identity()  # feature extractorë¡œë§Œ ì‚¬ìš©\n","        self.head = nn.Linear(self.feature_dim, num_classes)  # ë¶„ë¥˜ê¸°\n","\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        x = self.head(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"nXjsQGakPMEs"},"source":["# Train/ Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rPNtlPjGPMEs","outputId":"5cb5d34a-68bf-453b-9b13-8305541bb867"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 62.5MB/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[Execute Model Training on cuda]\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["[Epoch 1/10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [04:32<00:00,  1.52it/s]\n","[Epoch 1/10] Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:50<00:00,  2.05it/s]\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss : 4.1608 || Valid Loss : 2.2727 | Valid Accuracy : 70.5190%\n","ğŸ“¦ Best model saved at epoch 1 (logloss: 2.2713)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["[Epoch 2/10] Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 415/415 [04:13<00:00,  1.63it/s]\n","[Epoch 2/10] Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:48<00:00,  2.14it/s]\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Loss : 1.2921 || Valid Loss : 0.7625 | Valid Accuracy : 86.6476%\n","ğŸ“¦ Best model saved at epoch 2 (logloss: 0.7619)\n"]},{"output_type":"stream","name":"stderr","text":["[Epoch 3/10] Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 316/415 [03:11<00:57,  1.74it/s]"]}],"source":["model = BaseModel(num_classes=len(class_names)).to(device)\n","best_logloss = float('inf')\n","\n","print('[Execute Model Training on {}]'.format(device))\n","\n","# ì†ì‹¤ í•¨ìˆ˜\n","criterion = nn.CrossEntropyLoss()\n","\n","# ì˜µí‹°ë§ˆì´ì €\n","optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n","\n","\n","CFG['EPOCHS'] = 10\n","\n","# í•™ìŠµ ë° ê²€ì¦ ë£¨í”„\n","for epoch in range(CFG['EPOCHS']):\n","    # Train\n","    model.train()\n","    train_loss = 0.0\n","    for images, labels in tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)  # logits\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    avg_train_loss = train_loss / len(train_loader)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    all_probs = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            # Accuracy\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","            # LogLoss\n","            probs = F.softmax(outputs, dim=1)\n","            all_probs.extend(probs.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    avg_val_loss = val_loss / len(val_loader)\n","    val_accuracy = 100 * correct / total\n","    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n","\n","    # ê²°ê³¼ ì¶œë ¥\n","    print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.4f}%\")\n","\n","    # Best model ì €ì¥\n","    if val_logloss < best_logloss:\n","        best_logloss = val_logloss\n","        torch.save(model.state_dict(), f'best_model.pth')\n","        print(f\"ğŸ“¦ Best model saved at epoch {epoch+1} (logloss: {val_logloss:.4f})\")"]},{"cell_type":"markdown","metadata":{"id":"X3JuJ6MuPMEs"},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVWZtDNWPMEs"},"outputs":[],"source":["test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n","test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AR826n4RPMEs"},"outputs":[],"source":["# ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ\n","model = BaseModel(num_classes=len(class_names))\n","model.load_state_dict(torch.load('best_model.pth', map_location=device))\n","model.to(device)\n","\n","# ì¶”ë¡ \n","model.eval()\n","results = []\n","\n","with torch.no_grad():\n","    for images in test_loader:\n","        images = images.to(device)\n","        outputs = model(images)\n","        probs = F.softmax(outputs, dim=1)\n","\n","        # ê° ë°°ì¹˜ì˜ í™•ë¥ ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n","        for prob in probs.cpu():  # prob: (num_classes,)\n","            result = {\n","                class_names[i]: prob[i].item()\n","                for i in range(len(class_names))\n","            }\n","            results.append(result)\n","\n","pred = pd.DataFrame(results)"]},{"cell_type":"markdown","metadata":{"id":"Q3uvmWLaPMEt"},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqY5jhyqPMEt"},"outputs":[],"source":["submission = pd.read_csv('/content/dataset/sample_submission.csv', encoding='utf-8-sig')\n","\n","# 'ID' ì»¬ëŸ¼ì„ ì œì™¸í•œ í´ë˜ìŠ¤ ì»¬ëŸ¼ ì •ë ¬\n","class_columns = submission.columns[1:]\n","pred = pred[class_columns]\n","\n","submission[class_columns] = pred.values\n","submission.to_csv('/content/dataset/baseline_submission.csv', index=False, encoding='utf-8-sig')"]},{"cell_type":"code","source":[],"metadata":{"id":"ce-juuf5Z-Fp"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}